{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":8,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Dropout, Activation, MaxPooling2D, Flatten\nfrom keras.utils.np_utils import to_categorical\nfrom keras import optimizers\nfrom keras.regularizers import l1\nfrom keras.callbacks import ReduceLROnPlateau\nimport pandas as pd\nimport time","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(data_dir, is_train):\n    data = pd.read_csv(data_dir)\n    if is_train:\n        data    = data.sample(frac=1).reset_index(drop=True)\n        labels  = data[\"label\"]\n        labels  = to_categorical(labels)\n        data    = data.drop(\"label\", axis=1)\n        data    /= 255\n        return data, labels\n    else:\n        data /= 255\n        return data","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data_as_image(data_dir, is_train):\n    data = pd.read_csv(data_dir)\n    if is_train:\n        data = data.sample(frac=1).reset_index(drop=True)\n        labels = data[\"label\"]\n        labels = to_categorical(labels)\n        data = data.drop(\"label\", axis=1)\n        data /= 255\n        image_data = data.values\n        image_data = image_data.reshape((-1, 28, 28, 1))\n        return image_data, labels\n    else:\n        data /= 255\n        image_data = data.values\n        image_data = image_data.reshape((-1, 28, 28, 1))\n        return image_data","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(layer_size, input_shape, regularizer, drop_size, num_of_classes, lr):\n    model = Sequential()\n\n    model.add(Dense(layer_size, activity_regularizer=regularizer, input_shape=input_shape))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(drop_size))\n\n    model.add(Dense(layer_size, activity_regularizer=regularizer))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(drop_size))\n\n    model.add(Dense(num_of_classes))\n    model.add(Activation(\"softmax\"))\n\n    optimizer = optimizers.Adam(lr=lr)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_cnn_model(layer_size, input_shape, regularizer, drop_size, num_of_classes, lr):\n    model = Sequential()\n\n    model.add(Conv2D(layer_size, (3, 3), use_bias=False, input_shape=input_shape,\n                     activity_regularizer=regularizer))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(drop_size))\n\n    model.add(Conv2D(layer_size, (3, 3), use_bias=False, activity_regularizer=regularizer))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(drop_size))\n\n    model.add(Conv2D(layer_size, (3, 3), use_bias=False, activity_regularizer=regularizer))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(drop_size))\n\n    model.add(Flatten())\n    model.add(Dense(units=int(layer_size/8), use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(drop_size))\n\n    model.add(Dense(units=num_of_classes, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation('softmax'))\n\n    optimizer = optimizers.Adam(lr=lr)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dir  = \"/kaggle/input/digit-recognizer/train.csv\"\ntest_data_dir   = \"/kaggle/input/digit-recognizer/test.csv\"\n\ntrain_data, train_labels = read_data_as_image(train_data_dir, True)\ntest_data = read_data_as_image(test_data_dir, False)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_size      = 1024\n# input_shape     = [train_data.shape[1]]\ninput_shape     = (28, 28, 1)\nregularizer     = l1(0.001)\ndrop_size       = 0.2\nnum_of_classes  = 10\nlr              = 1e-5","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_cnn_model(layer_size, input_shape, regularizer, drop_size, num_of_classes, lr)\nmodel.summary()","execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Conv2D' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4e351e2f9f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-92586a62aecf>\u001b[0m in \u001b[0;36mbuild_cnn_model\u001b[0;34m(layer_size, input_shape, regularizer, drop_size, num_of_classes, lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     model.add(Conv2D(layer_size, (3, 3), use_bias=False, input_shape=input_shape,\n\u001b[0m\u001b[1;32m      5\u001b[0m                      activity_regularizer=regularizer))\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=1e-7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epochs   = 100\nval_split   = 0.2\nbatch_size  = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_data, train_labels, epochs=nb_epochs, validation_split=val_split,\n          batch_size=batch_size, verbose=1, callbacks=[reduce_lr])\n\nmodel.save(\"model\" + str(time.time()) + \".h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred    = model.predict(test_data)\npreds   = pred.argmax(axis=-1)\n\nresults = pd.DataFrame(preds, columns=[\"Label\"])\nresults.index += 1\nresults.to_csv(\"submission\" + str(time.time()) + \".csv\", index_label=\"ImageId\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}